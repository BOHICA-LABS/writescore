# Story 2.10: Implement Verb Morphosyntax Dimension

## Status

Proposed

## Story

**As a** data analyst using WriteScore,
**I want** to detect verb variety and sentence rhythm patterns in text,
**so that** I can identify AI-generated content which shows lower verb diversity, limited aspectual variation, and monotonous sentence rhythm compared to human writing.

## Acceptance Criteria

1. **Dimension Implementation**: New `VerbMorphosyntaxDimension` class implements `DimensionStrategy` interface with self-registration
2. **Verb Diversity Detection**: Calculates verb-specific lexical diversity metrics: Verb-TTR, Verb-MTLD, and vocd-D on verb stream
3. **Aspectual Profile Analysis**: Detects and quantifies distribution of progressive (be + V-ing), perfect (have + V-en), passive (be + V-en), and modal + V-infinitive constructions
4. **Sentence Rhythm Metrics**: Calculates clause length variance, T-unit variation (mean and SD), and subordination index (clauses per T-unit)
5. **Scoring Algorithm**: Returns 0-100 score where higher = more human-like. Primary signals: verb diversity (40%), aspectual distribution balance (30%), and sentence rhythm variance (30%)
6. **Performance**: Processes 10k words in < 20 seconds using spaCy dependency parsing and POS tagging
7. **Registry Integration**: Auto-registers with `DimensionRegistry` on module import
8. **Configuration**: Added to `full` profile as SUPPORTING tier dimension with 5% weight
9. **Testing**: Unit tests achieve > 80% code coverage with tests for all metric types
10. **Documentation**: Docstrings and inline comments explain metrics and research basis

## Tasks / Subtasks

- [ ] **Task 0**: Setup dependencies and verify spaCy model availability (AC: 6)
  - [ ] Subtask 0.1: Verify spaCy `en_core_web_sm` model is installed (or add to setup)
  - [ ] Subtask 0.2: Test POS tagging and dependency parsing on sample text
  - [ ] Subtask 0.3: Benchmark performance baseline for 10k words

- [ ] **Task 1**: Create `dimensions/verb_morphosyntax.py` with `VerbMorphosyntaxDimension` class (AC: 1, 2, 3, 4, 5, 10)
  - [ ] Subtask 1.1: Add comprehensive module docstring explaining dimension purpose and research basis
  - [ ] Subtask 1.2: Define class inheriting from `DimensionStrategy` with required properties
  - [ ] Subtask 1.3: Implement `dimension_name`, `weight` (5.0), `tier` (SUPPORTING), `description` properties
  - [ ] Subtask 1.4: Implement verb extraction using spaCy POS tags (VERB, AUX)
  - [ ] Subtask 1.5: Implement Verb-TTR calculation (distinct verbs / total verbs)
  - [ ] Subtask 1.6: Implement Verb-MTLD calculation (MTLD algorithm applied to verb stream only)
  - [ ] Subtask 1.7: Implement vocd-D calculation for verb diversity (optional, can use approximation)
  - [ ] Subtask 1.8: Implement aspectual pattern detection using dependency parsing:
    - Progressive: aux(be) + head(V-ing)
    - Perfect: aux(have) + head(V-en)
    - Passive: auxpass(be) + head(V-en)
    - Modal: aux(modal) + head(V-base)
  - [ ] Subtask 1.9: Calculate aspectual distribution metrics (normalized frequencies per 1k words)
  - [ ] Subtask 1.10: Implement clause segmentation using dependency tree
  - [ ] Subtask 1.11: Calculate clause length variance (SD of clause lengths in tokens)
  - [ ] Subtask 1.12: Calculate T-unit metrics (mean and SD of T-unit length)
  - [ ] Subtask 1.13: Calculate subordination index (total clauses / T-units)
  - [ ] Subtask 1.14: Implement `analyze()` method orchestrating all metrics
  - [ ] Subtask 1.15: Implement `calculate_score()` method with weighted components (verb diversity 40%, aspectual 30%, rhythm 30%)
  - [ ] Subtask 1.16: Implement `get_recommendations()` method providing actionable feedback
  - [ ] Subtask 1.17: Implement `get_tiers()` method defining score ranges

- [ ] **Task 2**: Add self-registration at module bottom (AC: 7)
  - [ ] Subtask 2.1: Call `DimensionRegistry.register(self)` in `__init__()` method
  - [ ] Subtask 2.2: Verify registration happens on import without errors

- [ ] **Task 3**: Integrate into `full` profile configuration (AC: 8)
  - [ ] Subtask 3.1: Add 'verb_morphosyntax': 'writescore.dimensions.verb_morphosyntax' to DIMENSION_MODULE_MAP
  - [ ] Subtask 3.2: Verify dimension appears in full profile analysis output

- [ ] **Task 4**: Create comprehensive unit tests (AC: 9)
  - [ ] Subtask 4.1: Create `tests/unit/dimensions/test_verb_morphosyntax.py`
  - [ ] Subtask 4.2: Test verb extraction from various text samples
  - [ ] Subtask 4.3: Test Verb-TTR calculation with known values
  - [ ] Subtask 4.4: Test Verb-MTLD calculation
  - [ ] Subtask 4.5: Test aspectual pattern detection (progressive, perfect, passive, modal)
  - [ ] Subtask 4.6: Test clause length variance calculation
  - [ ] Subtask 4.7: Test T-unit metrics calculation
  - [ ] Subtask 4.8: Test subordination index calculation
  - [ ] Subtask 4.9: Test scoring algorithm with human-like and AI-like samples
  - [ ] Subtask 4.10: Test edge cases (empty text, very short text, no verbs)
  - [ ] Subtask 4.11: Verify > 80% code coverage
  - [ ] Subtask 4.12: Benchmark performance on 10k word sample (verify < 20s)

- [ ] **Task 5**: Verify documentation completeness (AC: 10)
  - [ ] Subtask 5.1: Review module docstring for completeness and accuracy
  - [ ] Subtask 5.2: Review inline comments for clarity and research citations
  - [ ] Subtask 5.3: Verify all method docstrings follow project style

## Dev Notes

### Research Background

This dimension is based on established linguistic metrics from applied linguistics, L2 writing assessment, and AI text detection research. The key insight is that AI text tends to show:
- Lower verb diversity (repetitive verb usage)
- Imbalanced aspectual profiles (over/under-use of certain constructions)
- More uniform sentence rhythm (less variance in clause/sentence length)

### Metric Definitions

**Verb Diversity Metrics:**

1. **Verb-TTR (Type-Token Ratio)**: `distinct_verb_lemmas / total_verb_tokens`
   - Simple but affected by text length
   - Use as baseline metric

2. **Verb-MTLD (Measure of Textual Lexical Diversity)**:
   - Apply standard MTLD algorithm to verb stream only
   - More stable across text lengths than TTR
   - Threshold: 0.72 (standard MTLD threshold)

3. **vocd-D**:
   - Robust diversity measure using random sampling
   - Can use approximation: D ≈ (log(N) - log(V)) / log²(N) where N=tokens, V=types

**Aspectual Profile Metrics:**

| Construction | Pattern | Example |
|--------------|---------|---------|
| Progressive | be + V-ing | "is running", "was writing" |
| Perfect | have + V-en | "has completed", "had finished" |
| Passive | be + V-en | "was written", "is being done" |
| Modal | modal + V-base | "can run", "should write" |

Detection approach using spaCy dependency parsing:
```python
# Progressive: look for AUX "be" + VERB with -ing ending
# Perfect: look for AUX "have" + VERB with past participle tag
# Passive: look for auxpass dependency relation
# Modal: look for AUX with modal tag (MD) + VERB
```

**Sentence Rhythm Metrics:**

1. **Clause Length Variance**: Standard deviation of clause lengths (in tokens)
   - Higher variance = more rhythmic variety (human-like)
   - Low variance = monotonous rhythm (AI-like)

2. **T-unit Length**: Terminal unit = main clause + all attached subordinate clauses
   - Mean T-unit length: average tokens per T-unit
   - T-unit SD: standard deviation of T-unit lengths
   - Higher SD = more variety (human-like)

3. **Subordination Index**: Total clauses / Number of T-units
   - Measures embedding depth
   - Range typically 1.0-2.5 for written text
   - AI often shows lower subordination (simpler structures)

### Scoring Algorithm

```python
def calculate_score(self, metrics: Dict[str, Any]) -> float:
    """
    Calculate 0-100 score based on verb morphosyntax metrics.

    Components (research-based weights):
    - Verb diversity (40%): Higher Verb-MTLD = more human-like
    - Aspectual distribution (30%): Balanced distribution = more human-like
    - Sentence rhythm (30%): Higher variance = more human-like
    """
    # Verb diversity component (0-40 points)
    verb_mtld = metrics.get('verb_mtld', 0)
    # Target: MTLD > 50 for human-like verb diversity
    verb_score = min(40, (verb_mtld / 50) * 40)

    # Aspectual distribution component (0-30 points)
    # Calculate balance: entropy of aspectual distribution
    # More balanced = higher entropy = more human-like
    aspect_entropy = metrics.get('aspectual_entropy', 0)
    # Target: entropy > 1.5 for balanced distribution
    aspect_score = min(30, (aspect_entropy / 1.5) * 30)

    # Sentence rhythm component (0-30 points)
    clause_length_sd = metrics.get('clause_length_sd', 0)
    # Target: SD > 5 for natural rhythm variety
    rhythm_score = min(30, (clause_length_sd / 5) * 30)

    return verb_score + aspect_score + rhythm_score
```

### Expected Values by Text Type

| Metric | AI Text | Human Text | Target |
|--------|---------|------------|--------|
| Verb-TTR | 0.3-0.5 | 0.5-0.7 | > 0.5 |
| Verb-MTLD | 30-45 | 50-80 | > 50 |
| Progressive % | 2-5% | 5-15% | Balanced |
| Perfect % | 5-10% | 8-15% | Balanced |
| Passive % | 10-20% | 5-12% | < 15% |
| Clause Length SD | 2-4 | 4-8 | > 5 |
| T-unit SD | 3-5 | 5-10 | > 5 |
| Subordination Index | 1.1-1.3 | 1.3-1.8 | > 1.3 |

### Performance Considerations

- Use spaCy `en_core_web_sm` for speed (vs. `en_core_web_lg`)
- Cache parsed doc if text already parsed by other dimensions
- Process in batches for long texts if needed
- Target: < 20 seconds for 10k words (spaCy parsing is the bottleneck)

### Dependencies

- spaCy >= 3.0 (already a project dependency)
- en_core_web_sm model (already required)
- numpy (for statistical calculations)
- scipy (for entropy calculation, optional)

### Test Samples

```python
# Human-like sample (expected score: 75-90)
HUMAN_SAMPLE = """
The old mechanic had been working on engines for forty years. He was
examining the carburetor when I walked in, his calloused hands moving
with practiced precision. "This beauty needs a complete overhaul," he
muttered, wiping grease from his forehead. I watched as he dismantled
the assembly, cataloging each part mentally. His apprentice hurried
over, having finished the brake inspection. They debated repair
strategies while I waited, impressed by their methodical approach.
The shop hummed with activity as other technicians welded, diagnosed,
and tested various vehicles.
"""

# AI-like sample (expected score: 25-40)
AI_SAMPLE = """
The system utilizes advanced algorithms to process data. It analyzes
patterns and generates insights. The platform provides comprehensive
solutions. Users can leverage the features to optimize their workflows.
The tool offers robust functionality. It enables organizations to
streamline operations. The solution integrates seamlessly. It delivers
measurable results. The framework supports scalable implementations.
It facilitates efficient resource management.
"""
```

## Research Citations (Perplexity Deep Research)

### Full Research Response

The following comprehensive research was conducted using Perplexity's Sonar Reasoning Pro model to identify established linguistic/NLP metrics for verb variety, sentence rhythm/variation, and progressive forms:

---

**Query**: "Established linguistic / NLP metrics that quantify things like verb variety, sentence rhythm/variation, progressive forms, and that are relevant for AI-vs-human detection and writing analysis"

**Response**:

You're looking for **established linguistic / NLP metrics** that quantify things like **verb variety, sentence rhythm/variation, progressive forms**, and that are relevant for **AI-vs-human detection and writing analysis**.

Here are the main families of metrics and concrete measures to look at:

### 1. Verb variety and verb-related metrics

**Lexical / verb diversity**

- **Type-Token Ratio (TTR)** and its robust variants for lexical (incl. verb) diversity:
  - **MTLD (Measure of Textual Lexical Diversity)**[1]
  - **vocd-D**[1]
  - **HD-D, Maas** (often used together with MTLD and vocd-D)[1]
  These can be computed:
  - Globally (all lexical words), or
  - **Restricted to verbs only** (verb-type/verb-token; MTLD on verb stream) to get a **verb diversity** index.
- **SpeechAce / coherence.verb_diversity** (industry metric): measures how varied verbs are relative to a reference population[3].

**Verb difficulty / complexity (for research on verb forms)**

- **Frequency + phonological complexity of verbs**:
  - Use **corpus frequency** of verbs in specific morphosyntactic contexts (e.g., *V+ing*, *V+ed*, 3sg-s), not just lemma frequency.[2]
  - Use **Word Complexity Measure (WCM)** to score each verb's phonological complexity[2].
  These are used in experimental work to control/quantify **verb difficulty** and **verb variability** in contexts like *is/are + V-ing*, past *-ed*, etc.[2]

### 2. Sentence rhythm and variation

There is no single standard "sentence rhythm" metric, but several **syntax-based variation** measures are widely used in writing research and can be adapted:

- **Mean length of T-unit / clause** and **SD of clause length** → a proxy for **rhythmic variation** (short vs long units).
- **Subordination and coordination indices**:
  - Clauses per T-unit
  - Coordinate phrases per clause
- **Syntactic complexity indices** (often from Lu's syntactic complexity analyzer): various ratios of clause types that correlate with **sentence rhythm and complexity**.

For **accuracy** (relevant to L2 writing assessment and sometimes AI detection):

- **Error-free T-unit ratio (EFTR)** and **error-free clause ratio (EFCR)**: proportion of T-units/clauses with no errors[4].
- **Weighted Clause Ratio (WCR)**: a newer global metric of linguistic accuracy based on adequacy of meaning; compared against EFTR and EFCR as benchmarks[4].

These metrics, combined, provide a multi-dimensional profile of **fluency, variation, and correctness** in sentences.

### 3. Progressive / aspectual verb-form usage

To capture **progressive forms and aspect**:

- **Token and type counts** of:
  - **Progressive**: *be + V-ing* (is/are/was/were + V-ing)
  - **Perfect**: *have + V-en*
  - **Passive**: *be + V-en*
  - **Modal + V-infinitive*
- **Normalized frequencies** (e.g., per 1,000 words or per clause).
- **Distribution across contexts**, following the approach in verb-difficulty work:
  - Separate frequency lists for each morphosyntactic context (*V-ing*, *V-ed*, 3sg-s, bare form)[2].
- **Diversity within each aspectual category**:
  - MTLD / vocd-D computed **within the set of verbs in progressive form**, etc.

### 4. Metrics used in automated scoring / AI detection systems

Modern NLP scoring and AI-detection systems typically combine:

- **Lexical measures**
  - Global and POS-specific **lexical diversity** (MTLD, vocd-D)[1].
  - **Verb diversity** (distinct verb types per 100 verb tokens; or model-based verb_diversity metric as in SpeechAce)[3].
  - Lexical sophistication (proportion of low-frequency verbs).

- **Syntactic measures**
  - Syntactic complexity indices (clause/T-unit metrics, embedding depth).
  - Rhythm/variation proxies: variance in sentence and clause length, ratio of simple/complex sentences.

- **Morphosyntactic / aspectual patterns**
  - Relative rates of **progressive, perfect, passive**, modal, and simple forms.
  - Regularity and distribution of these patterns can serve as **stylometric features** for **AI-vs-human detection** (e.g., LLMs often over- or under-use certain aspectual patterns).

### 5. Practical set of metrics for your use case

If you are designing an **AI detection or writing analysis pipeline** focused on verbs and rhythm, a compact, research-grounded set would be:

- **Verb diversity**
  - Verb-only **MTLD** and **vocd-D**[1].
  - Simple **verb type-token ratio** (verb-TTR).

- **Verb difficulty & variability**
  - Corpus-based **frequency per verb form** (e.g., frequency of *V-ing* tokens by lemma)[2].
  - Optional: **WCM** scores for verbs (if phonological form matters, e.g., in spoken data)[2].

- **Aspect/tense profile**
  - Normalized counts of **progressive, perfect, passive, modal** constructions.
  - Diversity indices within progressive forms.

- **Sentence rhythm / variation**
  - Mean and SD of **sentence length** (tokens) and **clause length**.
  - Clauses per sentence; subordination index.
  - Proportion of short vs long sentences (e.g., <10 tokens, 10-25, >25).

- **Accuracy / well-formedness (optional but useful)**
  - **Error-free T-unit ratio**, **error-free clause ratio**, and/or **WCR**[4].

These are all **standard, citable metrics** in applied linguistics / L2 writing and can be computed with existing NLP pipelines (POS-tagging, dependency parsing, clause segmentation) plus diversity calculators based on MTLD/vocd-D.

### Sources

1. https://textinspector.com/help/lexical-diversity/
2. https://pmc.ncbi.nlm.nih.gov/articles/PMC10561966/
3. https://www.speechace.com/21-new-feedback-metrics-for-grammar-vocab-and-coherence/
4. https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=6776&context=facpub
5. https://people.ucsc.edu/~ktellez/poliowritingmeasures.pdf

---

### Additional Research Sources

**MTLD Algorithm**:
- McCarthy, P. M., & Jarvis, S. (2010). MTLD, vocd-D, and HD-D: A validation study of sophisticated approaches to lexical diversity assessment. Behavior Research Methods, 42(2), 381-392.

**Syntactic Complexity Analyzer (Lu)**:
- Lu, X. (2010). Automatic analysis of syntactic complexity in second language writing. International Journal of Corpus Linguistics, 15(4), 474-496.
- Web tool: https://aihaiyang.com/software/l2sca/

**T-unit Definition**:
- Hunt, K. W. (1970). Syntactic maturity in school children and adults. Monographs of the Society for Research in Child Development, 35(1), 1-67.

**AI Text Detection Patterns**:
- Recent research (2024-2025) shows AI text exhibits:
  - Lower verb diversity (repetitive verb choice)
  - Over-use of passive voice
  - Under-use of progressive aspect
  - More uniform clause lengths
  - Lower subordination index

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-09 | 0.1 | Initial story creation based on Perplexity research | Claude (via user request) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes

_To be populated upon completion_

### File List

**New Files:**
- `dimensions/verb_morphosyntax.py` - VerbMorphosyntaxDimension class implementation
- `tests/unit/dimensions/test_verb_morphosyntax.py` - Comprehensive unit tests

**Modified Files:**
- `core/dimension_loader.py` - Add verb_morphosyntax to DIMENSION_MODULE_MAP
